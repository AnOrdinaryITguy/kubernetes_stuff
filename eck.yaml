### Priority Classes ###
---
apiVersion: scheduling.k8s.io/v1
kind: PriorityClass
metadata:
  name: elastic-cluster-high-priority
value: 10000000
globalDefault: false
description: "This priority class should be used for elasticsearch cluster pods only."
---
apiVersion: scheduling.k8s.io/v1
kind: PriorityClass
metadata:
  name: filebeat-high-priority
value: 2000000
globalDefault: false
description: "This priority class should be used for filebeat pods only."
---
### Elasticsearch ###
apiVersion: elasticsearch.k8s.elastic.co/v1
kind: Elasticsearch
metadata:
  name: myelastic
spec:
  version: 8.12.1
  nodeSets:
  - name: master
    count: 2
    config:
      node.roles: ["master"]
    podTemplate:
      spec:
        priorityClassName: elastic-cluster-high-priority
        containers:
        - name: elasticsearch
          resources:
            limits:
              cpu: 1
              memory: 2Gi
            requests:
              cpu: 1
              memory: 2Gi
        initContainers:
        - name: sysctl
          securityContext:
            privileged: true
            runAsUser: 0
          command: ['sh', '-c', 'sysctl -w vm.max_map_count=262144']
  - name: data
    count: 1
    config:
      node.roles: ["data", "ingest"]
    podTemplate:
      spec:
        priorityClassName: elastic-cluster-high-priority
        containers:
        - name: elasticsearch
          resources:
            limits:
              cpu: 1
              memory: 2Gi
            requests:
              cpu: 1
              memory: 2Gi
        initContainers:
        - name: sysctl
          securityContext:
            privileged: true
            runAsUser: 0
          command: ['sh', '-c', 'sysctl -w vm.max_map_count=262144']
  - name: datawarm
    count: 1
    config:
      node.roles: ["data", "data_warm"]
    podTemplate:
          spec:
            priorityClassName: elastic-cluster-high-priority
            containers:
            - name: elasticsearch
              resources:
                limits:
                  cpu: 1
                  memory: 2Gi
                requests:
                  cpu: 1
                  memory: 2Gi
            initContainers:
            - name: sysctl
              securityContext:
                privileged: true
                runAsUser: 0
              command: ['sh', '-c', 'sysctl -w vm.max_map_count=262144']
  http:
    service:
      spec:
        type: LoadBalancer
        ports: 
        - protocol: TCP
          port: 9200
          targetPort: 9200
          name: https
---
### Kibana ###
apiVersion: kibana.k8s.elastic.co/v1
kind: Kibana
metadata:
  name: mykibana
spec:
  version: 8.12.1
  count: 1
  elasticsearchRef:
    name: myelastic
  config:
    xpack.fleet.agents.elasticsearch.hosts: ["https://myelastic-es-http.default.svc:9200"]
    xpack.fleet.agents.fleet_server.hosts: ["https://myfleet-agent-http.default.svc:8220"]
    xpack.fleet.packages:
      - name: system
        version: latest
      - name: elastic_agent
        version: latest
      - name: fleet_server
        version: latest
    xpack.fleet.agentPolicies:
      - name: Fleet Server on ECK policy
        id: eck-fleet-server
        namespace: default
        monitoring_enabled:
          - logs
          - metrics
        unenroll_timeout: 900
        package_policies:
        - name: fleet_server-1
          id: fleet_server-1
          package:
            name: fleet_server
      - name: Elastic Agent on ECK policy
        id: eck-agent
        namespace: default
        monitoring_enabled:
          - logs
          - metrics
        unenroll_timeout: 900
        package_policies:
          - name: system-1
            id: system-1
            package:
              name: system
  podTemplate:
    spec:
      priorityClassName: elastic-cluster-high-priority
      containers:
      - name: kibana
        env:
          - name: NODE_OPTIONS
            value: "--max-old-space-size=2048"
          - name: SERVER_PUBLICBASEURL
            value: "https://kibana.homelab"
        resources:
          limits:
            cpu: 1
            memory: 2Gi
          requests:
            cpu: 1
            memory: 2Gi
  http:
    service:
      spec:
        type: LoadBalancer
        ports: 
        - protocol: TCP
          port: 5601
          targetPort: 5601
          name: https
---
### Logstash ###
apiVersion: logstash.k8s.elastic.co/v1alpha1
kind: Logstash
metadata:
  name: mylogstash
spec:
  count: 1
  elasticsearchRefs:
    - name: myelastic
      clusterName: me #This is the reference that will be used in pipelineconfiguration
  version: 8.12.1
  pipelines:
    - pipeline.id: main
      config.string: |
        input {
          beats {
            port => 5044
          }
        }
        output {
          elasticsearch {
            hosts => [ "${ME_ES_HOSTS}" ]
            user => "${ME_ES_USER}"
            password => "${ME_ES_PASSWORD}"
            ssl_certificate_authorities => "${ME_ES_SSL_CERTIFICATE_AUTHORITY}"
          }
        }
  volumeClaimTemplates:
    - metadata:
        name: pq #Persitant queue to avoid data loss in case of powerloss
      spec:
        accessModes:
        - ReadWriteOnce
        resources:
          requests:
            storage: 10Gi
  podTemplate:
    spec:
      containers:
      - name: logstash
        resources:
            limits:
              cpu: 1
              memory: 2Gi
            requests:
              cpu: 1
              memory: 2Gi
        volumeMounts:
        - mountPath: /usr/share/logstash/pq 
          name: pq  
          readOnly: false
  config:
    log.level: info
    queue.type: persisted
    path.queue: /usr/share/logstash/pq       
  services:
    - name: beats
      service:
        spec:
          type: NodePort
          ports:
            - port: 5044
              name: "filebeat"
              protocol: TCP
              targetPort: 5044
---
### Fleet Server ###
apiVersion: agent.k8s.elastic.co/v1alpha1
kind: Agent
metadata:
  name: myfleet
  namespace: default
spec:
  version: 8.12.1
  kibanaRef:
    name: mykibana
  elasticsearchRefs:
  - name: myelastic
  mode: fleet
  fleetServerEnabled: true
  policyID: eck-fleet-server
  deployment:
    replicas: 1
    podTemplate:
      spec:
        serviceAccountName: elastic-agent
        automountServiceAccountToken: true
        securityContext:
          runAsUser: 0 
  http:
    service:
      spec:
        type: LoadBalancer
        ports: 
        - protocol: TCP
          port: 8220
          targetPort: 8220
          name: https
---
apiVersion: agent.k8s.elastic.co/v1alpha1
kind: Agent
metadata:
  name: myagent
  namespace: default
spec:
  version: 8.12.1
  kibanaRef:
    name: mykibana
  fleetServerRef:
    name: myfleet
  mode: fleet
  policyID: eck-agent
  daemonSet:
    podTemplate:
      spec:
        serviceAccountName: elastic-agent
        automountServiceAccountToken: true
        securityContext:
          runAsUser: 0 
        volumes:
        - name: agent-data
          emptyDir: {}
---
apiVersion: rbac.authorization.k8s.io/v1
kind: ClusterRole
metadata:
  name: elastic-agent
rules:
- apiGroups: [""] # "" indicates the core API group
  resources:
  - pods
  - nodes
  - namespaces
  verbs:
  - get
  - watch
  - list
- apiGroups: ["coordination.k8s.io"]
  resources:
  - leases
  verbs:
  - get
  - create
  - update
- apiGroups: ["apps"]
  resources:
  - replicasets
  verbs:
  - list
  - watch
- apiGroups: ["batch"]
  resources:
  - jobs
  verbs:
  - list
  - watch
### Roles ###
---
apiVersion: v1
kind: ServiceAccount
metadata:
  name: elastic-agent
  namespace: default
---
apiVersion: rbac.authorization.k8s.io/v1
kind: ClusterRoleBinding
metadata:
  name: elastic-agent
subjects:
- kind: ServiceAccount
  name: elastic-agent
  namespace: default
roleRef:
  kind: ClusterRole
  name: elastic-agent
  apiGroup: rbac.authorization.k8s.io
---